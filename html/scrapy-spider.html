<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-04-10 日 23:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Scrapy 爬虫的简单使用</title>
<meta name="author" content="Steiner" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
</style>
<link rel="stylesheet" type="text/css" href="../css/org.css"/>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Scrapy 爬虫的简单使用</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org78568bf">1. 简单的爬虫流程</a></li>
<li><a href="#orga3a44f3">2. Scrapy 如何扩展这一流程</a></li>
<li><a href="#org23431ce">3. Scrapy 简单示例</a>
<ul>
<li><a href="#orgab08464">3.1. 准备项目</a></li>
<li><a href="#orgb50cd56">3.2. 基础设定</a></li>
<li><a href="#org1e185c0">3.3. 添加命令行参数</a></li>
<li><a href="#org2e5e2de">3.4. 解析函数 parseAlbum</a></li>
<li><a href="#orga7c6a64">3.5. 解析函数 parse</a></li>
<li><a href="#org5b2fac3">3.6. Pipeline 处理结果</a></li>
<li><a href="#org6aea215">3.7. 全局设置</a>
<ul>
<li><a href="#org3bf4f4e">3.7.1. 开启 pipeline</a></li>
<li><a href="#org92555ca">3.7.2. 设置 文件存贮 默认位置</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org78568bf" class="outline-2">
<h2 id="org78568bf"><span class="section-number-2">1.</span> 简单的爬虫流程</h2>
<div class="outline-text-2" id="text-1">
<p>
一般的，程序向网站请求网页<br />
</p>
<div class="org-center">
<p>
程序 =========&gt; 网站<br />
</p>
</div>
<p>
而后，网站返回网页与程序<br />
</p>
<div class="org-center">
<p>
程序 &lt;========= 网站<br />
</p>
</div>
<p>
接着程序负责解析得到的 <b>HTML</b> 数据即可<br />
</p>
</div>
</div>
<div id="outline-container-orga3a44f3" class="outline-2">
<h2 id="orga3a44f3"><span class="section-number-2">2.</span> Scrapy 如何扩展这一流程</h2>
<div class="outline-text-2" id="text-2">
<p>
程序请求网页时， <code>scrapy</code> 添加了中间件在双方之间<br />
</p>
<div class="org-center">
<p>
程序 =====&gt; 中间件 ======&gt; 网站<br />
</p>
</div>
<p>
网站返回数据时，也需要通过中间件<br />
</p>
<div class="org-center">
<p>
程序 &lt;===== 中间件 &lt;====== 网站<br />
</p>
</div>

<p>
程序解析完数据后，不会马上处理数据，而是把一个网页的数据打包成一个 <code>Item</code> 数据，传递给 <code>pipeline</code> 处理<br />
</p>
<div class="org-center">
<p>
pipeline &lt;==== item &lt;==== 程序<br />
</p>
</div>
</div>
</div>
<div id="outline-container-org23431ce" class="outline-2">
<h2 id="org23431ce"><span class="section-number-2">3.</span> Scrapy 简单示例</h2>
<div class="outline-text-2" id="text-3">
<p>
这里以爬取美图录的图片为例(注意，我不打算用默认的 <code>start_urls</code> 数据)<br />
首先我们到一个模特的主页上，比如<br />
</p>

<p>
<img src="../../../ChiniBlogs/src/images/Scrapy_简单示例/2022-04-10_20-13-21_screenshot.png" alt="2022-04-10_20-13-21_screenshot.png" /><br />
接下来我们要从这个 <b>指定模特页面</b> 上的每一个专辑上爬取图片<br />
</p>
</div>

<div id="outline-container-orgab08464" class="outline-3">
<h3 id="orgab08464"><span class="section-number-3">3.1.</span> 准备项目</h3>
<div class="outline-text-3" id="text-3-1">
<ol class="org-ol">
<li><p>
安装 <code>scrapy</code><br />
</p>
<div class="org-src-container">
<pre class="src src-bash">sudo pip3 install scrapy
</pre>
</div></li>

<li><p>
创建新项目<br />
</p>
<div class="org-src-container">
<pre class="src src-bash">scrapy startproject meitulu
</pre>
</div></li>
</ol>
</div>
</div>
<div id="outline-container-orgb50cd56" class="outline-3">
<h3 id="orgb50cd56"><span class="section-number-3">3.2.</span> 基础设定</h3>
<div class="outline-text-3" id="text-3-2">
<p>
在 <code>meitulu/spiders/</code> 下我们新建一个爬虫文件 <code>evelyn.py</code><br />
</p>
<div class="org-src-container">
<pre class="src src-python">class Spider(scrapy.Spider):
    name = 'evelyn'

</pre>
</div>

<p>
其中的 <code>name</code> 属性是为了调用的时候能找到爬虫位置，比如调用这个爬虫的时候，我们指定 <code>name</code><br />
</p>
<div class="org-src-container">
<pre class="src src-bash">scrapy crawl evelyn
</pre>
</div>
</div>
</div>

<div id="outline-container-org1e185c0" class="outline-3">
<h3 id="org1e185c0"><span class="section-number-3">3.3.</span> 添加命令行参数</h3>
<div class="outline-text-3" id="text-3-3">
<div class="org-src-container">
<pre class="src src-python">def __init__(self, albumUrl=None, *args, **kwargs):
    if albumUrl == None:
	raise Exception('usage: -a albumUrl=...')

    super(Spider, self).__init__(*args, **kwargs)
    self.start_url = albumUrl

def start_requests(self):
    yield scrapy.Request(url=self.start_url, callback=self.parse)

</pre>
</div>

<p>
这里在类的 <code>__init__</code> 方法上我们做了修改，第二个参数是命令行参数名称，默认为 <code>None</code> ，第三，第四个参数不需要管<br />
我们这样调用<br />
</p>
<div class="org-src-container">
<pre class="src src-bash">scrapy crawl evelyn -a albumUrl='http://meitulu.cn/t/Evelynaili/'
</pre>
</div>

<p>
注意这里我们没有定义 <code>start_urls</code> 而是 <code>start_url</code> ，这里我覆盖了这种默认行为，重新定义了 <code>start_requests</code> <br />
并将获取到的响应交给 <code>self.parse</code> 回调来解析<br />
</p>
</div>
</div>

<div id="outline-container-org2e5e2de" class="outline-3">
<h3 id="org2e5e2de"><span class="section-number-3">3.4.</span> 解析函数 parseAlbum</h3>
<div class="outline-text-3" id="text-3-4">
<p>
这里的函数解析一张专辑中的每一张图片，然后解析出 <code>item</code> ，传递给 <code>pipeline</code> ，如果有下一页，继续请求<br />
</p>
<div class="org-src-container">
<pre class="src src-python">def parseAlbum(self, response, firstUrl, albumName, count):
    url = response.css('div.content center a img.content_img::attr(src)').extract_first()
    name = str(count) + '.jpg'

    yield Image(url=url, name=name, albumName=albumName, fromUrl=response.url)

    nextPage = response.urljoin(response.css('div.content center a::attr(href)').extract_first())
    if nextPage != firstUrl:
	yield scrapy.Request(
	    url=nextPage,
	    callback=self.parseAlbum,
	    cb_kwargs=dict(firstUrl=nextPage, albumName=albumName, count=count+1))
</pre>
</div>
<p>
在函数中，<br />
</p>
<ul class="org-ul">
<li><code>firstUrl</code><br />
表示专辑的第一页网址，也是专辑的入口地址，设置他是因为最后一页的下一页是 <code>firstUrl</code> ，<br />
需要用来判断当前页是否为最后一页<br /></li>
<li><code>albumName</code><br />
表示专辑名称，设置他是因为我看了下html代码，每一张图片的 <code>alt</code> 属性都是专辑名，为其命名也麻烦<br /></li>
<li><code>count</code><br />
所以我就设置了这个参数，需要请求下一页的时候，这个参数就加1<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orga7c6a64" class="outline-3">
<h3 id="orga7c6a64"><span class="section-number-3">3.5.</span> 解析函数 parse</h3>
<div class="outline-text-3" id="text-3-5">
<p>
这个函数获取模特主页中每一张专辑的地址，然后传递给 <code>self.parseAlbum</code> 回调，并通过 <code>cb_kwargs</code> 添加额外的函数参数<br />
</p>
<div class="org-src-container">
<pre class="src src-python">def parse(self, response):
    urls = response.css('div.main div.boxs ul.img li&gt;a::attr(href)').extract()
    albumUrls = list(map(lambda url: response.urljoin(url), urls))
    names = response.css('div.main div.boxs ul.img li p.p_title&gt; a::text').extract()

    for (albumUrl, name) in zip(albumUrls, names):
	yield scrapy.Request(
	    url=albumUrl,
	    callback=self.parseAlbum,
	    cb_kwargs=dict(firstUrl=albumUrl, albumName=name, count=1))

</pre>
</div>
</div>
</div>

<div id="outline-container-org5b2fac3" class="outline-3">
<h3 id="org5b2fac3"><span class="section-number-3">3.6.</span> Pipeline 处理结果</h3>
<div class="outline-text-3" id="text-3-6">
<p>
由于直接请求图片会被网站检测，并返回 403 代码，这里我们伪造下请求头<br />
</p>
<div class="org-src-container">
<pre class="src src-python">default_headers = {
    'Accept': 'image/avif,image/webp,*/*',
    'Accept-Encoding': 'gzip, deflate',
    'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
    'Host': 'image.meitulu.cn',
    'Referer': 'http://meitulu.cn/',
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:99.0) Gecko/20100101 Firefox/99.0'
}
</pre>
</div>

<p>
接下来我们写一个类来继承 <code>FilesPipeline</code> ，处理结果<br />
</p>
<div class="org-src-container">
<pre class="src src-python">from scrapy.pipelines.images import FilesPipeline

class MeituluPipeline(FilesPipeline):
    default_headers = {
	'Accept': 'image/avif,image/webp,*/*',
	'Accept-Encoding': 'gzip, deflate',
	'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
	'Host': 'image.meitulu.cn',
	'Referer': 'http://meitulu.cn/',
	'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:99.0) Gecko/20100101 Firefox/99.0'
    }

    def file_path(self, request, response=None, info=None, *, item=None):
	dirname = item['albumName']
	basename = item['name']

	return os.path.join(dirname, basename)

    def get_media_requests(self, item, info):
	yield scrapy.Request(item['url'], headers=self.default_headers)

    def item_completed(self, results, item, info):
	return item
</pre>
</div>

<p>
其中有三个函数可以挑选着来重写<br />
</p>
<ul class="org-ul">
<li><code>file_path</code><br />
指定 <code>item</code> 存贮的文件名<br /></li>
<li><code>get_media_requests</code><br />
自定义如何请求图片的函数<br /></li>
<li><code>item_completed</code><br />
下载完图片后如何处理<br /></li>
</ul>
<p>
另外这个 <code>file_path</code> 的重写我忘了从哪个教程里粘贴过来的了，先用着吧<br />
</p>
</div>
</div>
<div id="outline-container-org6aea215" class="outline-3">
<h3 id="org6aea215"><span class="section-number-3">3.7.</span> 全局设置</h3>
<div class="outline-text-3" id="text-3-7">
</div>
<div id="outline-container-org3bf4f4e" class="outline-4">
<h4 id="org3bf4f4e"><span class="section-number-4">3.7.1.</span> 开启 pipeline</h4>
<div class="outline-text-4" id="text-3-7-1">
<div class="org-src-container">
<pre class="src src-python">ITEM_PIPELINES = {
   'meitulu.pipelines.MeituluPipeline': 300,
}

</pre>
</div>
</div>
</div>

<div id="outline-container-org92555ca" class="outline-4">
<h4 id="org92555ca"><span class="section-number-4">3.7.2.</span> 设置 文件存贮 默认位置</h4>
<div class="outline-text-4" id="text-3-7-2">
<div class="org-src-container">
<pre class="src src-python">FILES_STORE = '/home/steiner/workspace/meitulu/capture/'
</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Steiner</p>
<p class="date">Created: 2022-04-10 日 23:20</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>